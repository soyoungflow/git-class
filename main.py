# from urllib.parse import urlparse, parse_qs

# url = "https://google.com/search?q=python&page=2"

# parsed_url = urlparse(url)
# params = parse_qs(parsed_url.query)

# print("ì „ì²´ URL:", url)
# print("ê²½ë¡œ(Path):", parsed_url.path)
# print("ì¿¼ë¦¬(Query):", parsed_url.query)
# print("ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°:", params)

# items = ["ì‚¬ê³¼", "ë°”ë‚˜ë‚˜", "ë”¸ê¸°", "í¬ë„", "ìˆ˜ë°•"]

# def get_items(skip=0, limit=2):
#     return items[skip: skip + limit]

# print(get_items(skip=1, limit=3))  
# # ['ë°”ë‚˜ë‚˜', 'ë”¸ê¸°', 'í¬ë„']

import requests

urls = [
    "https://google.com",                # 200 OK
    "https://google.com/nonexist",       # 404 Not Found
    "https://httpbin.org/status/500",    # 500 Internal Server Error
    "https://httpbin.org/status/302"     # 302 Redirect
]

for url in urls:
    response = requests.get(url)
    print(f"URL: {url}")
    print("Status Code:", response.status_code)

    if response.status_code == 200:
        print("â†’ ì •ìƒì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤! ğŸ˜Š")
    elif response.status_code == 404:
        print("â†’ ì£¼ì†Œê°€ ì˜ëª»ë˜ì—ˆë‚˜ë´ìš”! ğŸ˜¢ í˜ì´ì§€ê°€ ì—†ì–´ìš”.")
    elif response.status_code == 500:
        print("â†’ ì„œë²„ê°€ ì•„íŒŒìš”! ê°œë°œìê°€ ê³ ì³ì•¼ í•´ìš” âš ï¸")
    elif 300 <= response.status_code < 400:
        print("â†’ ë‹¤ë¥¸ í˜ì´ì§€ë¡œ ì´ë™ì‹œí‚¤ê³  ìˆì–´ìš” ğŸ”")
    
    print("-" * 50)

